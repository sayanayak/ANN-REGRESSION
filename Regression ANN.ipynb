{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>MetColor</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FuelType_CNG</th>\n",
       "      <th>FuelType_Diesel</th>\n",
       "      <th>FuelType_Petrol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13500</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46986</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13750</td>\n",
       "      <td>23.0</td>\n",
       "      <td>72937</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13950</td>\n",
       "      <td>24.0</td>\n",
       "      <td>41711</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14950</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13750</td>\n",
       "      <td>30.0</td>\n",
       "      <td>38500</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price   Age     KM  HP  MetColor  Automatic      CC  Doors  Weight  \\\n",
       "0  13500  23.0  46986  90         1          0  2000.0      3  1165.0   \n",
       "1  13750  23.0  72937  90         1          0  2000.0      3  1165.0   \n",
       "2  13950  24.0  41711  90         1          0  2000.0      3  1165.0   \n",
       "3  14950  26.0  48000  90         0          0  2000.0      3  1165.0   \n",
       "4  13750  30.0  38500  90         0          0  2000.0      3  1170.0   \n",
       "\n",
       "   FuelType_CNG  FuelType_Diesel  FuelType_Petrol  \n",
       "0             0                1                0  \n",
       "1             0                1                0  \n",
       "2             0                1                0  \n",
       "3             0                1                0  \n",
       "4             0                1                0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the cleaned numeric car prices data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# To remove the scientific notation from numpy arrays\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "CarPricesDataNumeric=pd.read_pickle('CarPricesDataNumeric.pkl')\n",
    "CarPricesDataNumeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Standardization of data\n",
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable=['Price']\n",
    "Predictors=['Age', 'KM', 'HP', 'MetColor', 'Automatic', 'CC', 'Doors',\n",
    "       'Weight', 'FuelType_CNG', 'FuelType_Diesel', 'FuelType_Petrol']\n",
    "\n",
    "X=CarPricesDataNumeric[Predictors].values\n",
    "y=CarPricesDataNumeric[TargetVariable].values\n",
    "\n",
    "\n",
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(y)\n",
    "\n",
    "# Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "y=TargetVarScalerFit.transform(y)\n",
    "\n",
    "\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 11)\n",
      "(999, 1)\n",
      "(429, 11)\n",
      "(429, 1)\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity check with the shapes of Training and testing datasets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.79400224, -0.58190964, -0.76628391,  0.69377792, -0.24361277,\n",
       "         2.34607519, -1.08412485,  2.10364977, -0.10976426,  2.92982809,\n",
       "        -2.75724675],\n",
       "       [-1.79400224,  0.11238127, -0.76628391,  0.69377792, -0.24361277,\n",
       "         2.34607519, -1.08412485,  2.10364977, -0.10976426,  2.92982809,\n",
       "        -2.75724675],\n",
       "       [-1.73978236, -0.72303656, -0.76628391,  0.69377792, -0.24361277,\n",
       "         2.34607519, -1.08412485,  2.10364977, -0.10976426,  2.92982809,\n",
       "        -2.75724675]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardized predictors\n",
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   23., 46986.,    90.,     1.,     0.,  2000.,     3.,  1165.,\n",
       "            0.,     1.,     0.],\n",
       "       [   23., 72937.,    90.,     1.,     0.,  2000.,     3.,  1165.,\n",
       "            0.,     1.,     0.],\n",
       "       [   24., 41711.,    90.,     1.,     0.,  2000.,     3.,  1165.,\n",
       "            0.,     1.,     0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverse transform will take the data back to original form\n",
    "PredictorScalerFit.inverse_transform(X)[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression using Deep Learning- Artificial Neural Networks(ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ANN model\n",
    "model = Sequential()\n",
    "\n",
    "# Defining the first layer of the model\n",
    "model.add(Dense(units=5, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
    "\n",
    "\n",
    "# The output neuron is a single fully connected node \n",
    "# Since we will be predicting a single number\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "999/999 [==============================] - 5s 5ms/step - loss: 1.0220\n",
      "Epoch 2/50\n",
      "999/999 [==============================] - 0s 487us/step - loss: 0.9529\n",
      "Epoch 3/50\n",
      "999/999 [==============================] - 1s 558us/step - loss: 0.7355\n",
      "Epoch 4/50\n",
      "999/999 [==============================] - 1s 602us/step - loss: 0.4762\n",
      "Epoch 5/50\n",
      "999/999 [==============================] - 1s 593us/step - loss: 0.3125\n",
      "Epoch 6/50\n",
      "999/999 [==============================] - 1s 543us/step - loss: 0.2374\n",
      "Epoch 7/50\n",
      "999/999 [==============================] - 1s 602us/step - loss: 0.1964 0s - loss\n",
      "Epoch 8/50\n",
      "999/999 [==============================] - 1s 585us/step - loss: 0.1714\n",
      "Epoch 9/50\n",
      "999/999 [==============================] - 1s 569us/step - loss: 0.1563 0s - los\n",
      "Epoch 10/50\n",
      "999/999 [==============================] - 1s 513us/step - loss: 0.1465\n",
      "Epoch 11/50\n",
      "999/999 [==============================] - 0s 472us/step - loss: 0.1412\n",
      "Epoch 12/50\n",
      "999/999 [==============================] - 0s 481us/step - loss: 0.1389\n",
      "Epoch 13/50\n",
      "999/999 [==============================] - 1s 521us/step - loss: 0.1348\n",
      "Epoch 14/50\n",
      "999/999 [==============================] - 1s 521us/step - loss: 0.1322\n",
      "Epoch 15/50\n",
      "999/999 [==============================] - 1s 513us/step - loss: 0.1300\n",
      "Epoch 16/50\n",
      "999/999 [==============================] - 1s 601us/step - loss: 0.1290\n",
      "Epoch 17/50\n",
      "999/999 [==============================] - 0s 454us/step - loss: 0.1265\n",
      "Epoch 18/50\n",
      "999/999 [==============================] - 0s 485us/step - loss: 0.1258\n",
      "Epoch 19/50\n",
      "999/999 [==============================] - 0s 464us/step - loss: 0.1236\n",
      "Epoch 20/50\n",
      "999/999 [==============================] - 1s 506us/step - loss: 0.1246\n",
      "Epoch 21/50\n",
      "999/999 [==============================] - 0s 444us/step - loss: 0.1216\n",
      "Epoch 22/50\n",
      "999/999 [==============================] - 1s 577us/step - loss: 0.1206\n",
      "Epoch 23/50\n",
      "999/999 [==============================] - 1s 529us/step - loss: 0.1195\n",
      "Epoch 24/50\n",
      "999/999 [==============================] - 1s 535us/step - loss: 0.1191\n",
      "Epoch 25/50\n",
      "999/999 [==============================] - 1s 617us/step - loss: 0.1189 0s - loss: 0.11\n",
      "Epoch 26/50\n",
      "999/999 [==============================] - 1s 585us/step - loss: 0.1173\n",
      "Epoch 27/50\n",
      "999/999 [==============================] - 1s 569us/step - loss: 0.1166\n",
      "Epoch 28/50\n",
      "999/999 [==============================] - 1s 569us/step - loss: 0.1158\n",
      "Epoch 29/50\n",
      "999/999 [==============================] - 1s 529us/step - loss: 0.1155\n",
      "Epoch 30/50\n",
      "999/999 [==============================] - 0s 497us/step - loss: 0.1145\n",
      "Epoch 31/50\n",
      "999/999 [==============================] - 0s 473us/step - loss: 0.1142 0s - loss: 0\n",
      "Epoch 32/50\n",
      "999/999 [==============================] - 0s 473us/step - loss: 0.1133\n",
      "Epoch 33/50\n",
      "999/999 [==============================] - 1s 513us/step - loss: 0.1126\n",
      "Epoch 34/50\n",
      "999/999 [==============================] - 1s 569us/step - loss: 0.1121\n",
      "Epoch 35/50\n",
      "999/999 [==============================] - 1s 529us/step - loss: 0.1118\n",
      "Epoch 36/50\n",
      "999/999 [==============================] - 1s 513us/step - loss: 0.1110\n",
      "Epoch 37/50\n",
      "999/999 [==============================] - 1s 529us/step - loss: 0.1108\n",
      "Epoch 38/50\n",
      "999/999 [==============================] - 0s 465us/step - loss: 0.1108\n",
      "Epoch 39/50\n",
      "999/999 [==============================] - 0s 489us/step - loss: 0.1105\n",
      "Epoch 40/50\n",
      "999/999 [==============================] - 1s 529us/step - loss: 0.1100\n",
      "Epoch 41/50\n",
      "999/999 [==============================] - 0s 497us/step - loss: 0.1085\n",
      "Epoch 42/50\n",
      "999/999 [==============================] - 0s 465us/step - loss: 0.1100\n",
      "Epoch 43/50\n",
      "999/999 [==============================] - 0s 485us/step - loss: 0.1085\n",
      "Epoch 44/50\n",
      "999/999 [==============================] - 0s 481us/step - loss: 0.1077 0s - loss: 0.108\n",
      "Epoch 45/50\n",
      "999/999 [==============================] - 0s 481us/step - loss: 0.1073\n",
      "Epoch 46/50\n",
      "999/999 [==============================] - 1s 545us/step - loss: 0.1072\n",
      "Epoch 47/50\n",
      "999/999 [==============================] - 1s 545us/step - loss: 0.1081\n",
      "Epoch 48/50\n",
      "999/999 [==============================] - 0s 465us/step - loss: 0.1072\n",
      "Epoch 49/50\n",
      "999/999 [==============================] - 0s 448us/step - loss: 0.1069\n",
      "Epoch 50/50\n",
      "999/999 [==============================] - 0s 464us/step - loss: 0.1066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xf817689e48>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "#1000/20 --- forward/backward\n",
    "model.fit(X_train, y_train ,batch_size = 20, epochs = 50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding best set of parameters using manual grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list=[5, 10, 15, 20]\n",
    "    epoch_list  =   [5, 10, 50, 100]\n",
    "    \n",
    "    import pandas as pd\n",
    "    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
    "    \n",
    "    # initializing the trials\n",
    "    TrialNumber=0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber+=1\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=10, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=5, input_dim=20, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = 10, verbose=0)\n",
    "\n",
    "            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
    "            \n",
    "            # printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n",
    "            \n",
    "            SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n",
    "                                                                    columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n",
    "    return(SearchResultsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Parameters: batch_size: 5 - epochs: 5 Accuracy: 82.72656924069275\n",
      "2 Parameters: batch_size: 5 - epochs: 10 Accuracy: 78.74907303908995\n",
      "3 Parameters: batch_size: 5 - epochs: 50 Accuracy: 78.92280913991384\n",
      "4 Parameters: batch_size: 5 - epochs: 100 Accuracy: 81.64888015322423\n",
      "5 Parameters: batch_size: 10 - epochs: 5 Accuracy: 77.34253691939816\n",
      "6 Parameters: batch_size: 10 - epochs: 10 Accuracy: 78.9927227950354\n",
      "7 Parameters: batch_size: 10 - epochs: 50 Accuracy: 78.10293716754748\n",
      "8 Parameters: batch_size: 10 - epochs: 100 Accuracy: 78.13029941917682\n",
      "9 Parameters: batch_size: 15 - epochs: 5 Accuracy: 76.02403965877997\n",
      "10 Parameters: batch_size: 15 - epochs: 10 Accuracy: 78.2984791310606\n",
      "11 Parameters: batch_size: 15 - epochs: 50 Accuracy: 77.19526157607554\n",
      "12 Parameters: batch_size: 15 - epochs: 100 Accuracy: 78.19416655746379\n",
      "13 Parameters: batch_size: 20 - epochs: 5 Accuracy: 73.73941185218938\n",
      "14 Parameters: batch_size: 20 - epochs: 10 Accuracy: 72.1588938286892\n",
      "15 Parameters: batch_size: 20 - epochs: 50 Accuracy: 74.59692834106832\n",
      "16 Parameters: batch_size: 20 - epochs: 100 Accuracy: 74.37035698120927\n"
     ]
    }
   ],
   "source": [
    "# Calling the function\n",
    "ResultsData=FunctionFindBestParams(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAYAN\\anaconda0\\lib\\site-packages\\pandas\\plotting\\_matplotlib\\core.py:1235: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(xticklabels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Parameters'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ResultsData.plot(x='Parameters', y='Accuracy', figsize=(15,4), kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xf809249188>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train ,batch_size = 5, epochs = 5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>MetColor</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FuelType_CNG</th>\n",
       "      <th>FuelType_Diesel</th>\n",
       "      <th>FuelType_Petrol</th>\n",
       "      <th>Price</th>\n",
       "      <th>PredictedPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>16812.841797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>89520.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8950.0</td>\n",
       "      <td>7863.892578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>66777.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11950.0</td>\n",
       "      <td>10750.361328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>24723.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12695.0</td>\n",
       "      <td>12757.428711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>9312.664062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age       KM     HP  MetColor  Automatic      CC  Doors  Weight  \\\n",
       "0  20.0  35000.0   97.0       1.0        0.0  1400.0    5.0  1110.0   \n",
       "1  76.0  89520.0  110.0       1.0        0.0  1600.0    3.0  1050.0   \n",
       "2  56.0  66777.0  110.0       0.0        0.0  1600.0    5.0  1090.0   \n",
       "3  39.0  24723.0  110.0       1.0        1.0  1600.0    4.0  1060.0   \n",
       "4  68.0  35000.0  110.0       1.0        0.0  1600.0    3.0  1050.0   \n",
       "\n",
       "   FuelType_CNG  FuelType_Diesel  FuelType_Petrol    Price  PredictedPrice  \n",
       "0           0.0              0.0              1.0  16500.0    16812.841797  \n",
       "1           0.0              0.0              1.0   8950.0     7863.892578  \n",
       "2           0.0              0.0              1.0  11950.0    10750.361328  \n",
       "3           0.0              0.0              1.0  12695.0    12757.428711  \n",
       "4           0.0              0.0              1.0   8900.0     9312.664062  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions on testing data\n",
    "Predictions=model.predict(X_test)\n",
    "\n",
    "# Scaling the predicted Price data back to original price scale\n",
    "Predictions=TargetVarScalerFit.inverse_transform(Predictions)\n",
    "\n",
    "# Scaling the y_test Price data back to original price scale\n",
    "y_test_orig=TargetVarScalerFit.inverse_transform(y_test)\n",
    "\n",
    "# Scaling the test data back to original scale\n",
    "Test_Data=PredictorScalerFit.inverse_transform(X_test)\n",
    "\n",
    "TestingData=pd.DataFrame(data=Test_Data, columns=Predictors)\n",
    "TestingData['Price']=y_test_orig\n",
    "TestingData['PredictedPrice']=Predictions\n",
    "TestingData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>MetColor</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FuelType_CNG</th>\n",
       "      <th>FuelType_Diesel</th>\n",
       "      <th>FuelType_Petrol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>8950</td>\n",
       "      <td>76.0</td>\n",
       "      <td>89520</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price   Age     KM   HP  MetColor  Automatic      CC  Doors  Weight  \\\n",
       "1197   8950  76.0  89520  110         1          0  1600.0      3  1050.0   \n",
       "\n",
       "      FuelType_CNG  FuelType_Diesel  FuelType_Petrol  \n",
       "1197             0                0                1  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing a sample row from original data to confirm if the reverse transform has happend correctly\n",
    "CarPricesDataNumeric[CarPricesDataNumeric['KM']==89520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy of ANN model is: 92.07068653583799\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>MetColor</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FuelType_CNG</th>\n",
       "      <th>FuelType_Diesel</th>\n",
       "      <th>FuelType_Petrol</th>\n",
       "      <th>Price</th>\n",
       "      <th>PredictedPrice</th>\n",
       "      <th>APE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>16812.841797</td>\n",
       "      <td>1.896011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.0</td>\n",
       "      <td>89520.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8950.0</td>\n",
       "      <td>7863.892578</td>\n",
       "      <td>12.135278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>66777.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11950.0</td>\n",
       "      <td>10750.361328</td>\n",
       "      <td>10.038817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>24723.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12695.0</td>\n",
       "      <td>12757.428711</td>\n",
       "      <td>0.491758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8900.0</td>\n",
       "      <td>9312.664062</td>\n",
       "      <td>4.636675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.0</td>\n",
       "      <td>104299.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8495.0</td>\n",
       "      <td>8639.937500</td>\n",
       "      <td>1.706151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67.0</td>\n",
       "      <td>79762.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9130.0</td>\n",
       "      <td>8256.042969</td>\n",
       "      <td>9.572366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.0</td>\n",
       "      <td>47768.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10850.0</td>\n",
       "      <td>10543.637695</td>\n",
       "      <td>2.823616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28.0</td>\n",
       "      <td>29206.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15950.0</td>\n",
       "      <td>15825.493164</td>\n",
       "      <td>0.780607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50.0</td>\n",
       "      <td>39706.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>11556.009766</td>\n",
       "      <td>14.399928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41.0</td>\n",
       "      <td>30989.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12200.0</td>\n",
       "      <td>12622.322266</td>\n",
       "      <td>3.461658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>66.0</td>\n",
       "      <td>39144.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8250.0</td>\n",
       "      <td>9418.009766</td>\n",
       "      <td>14.157694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>77.0</td>\n",
       "      <td>90305.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>7330.746094</td>\n",
       "      <td>5.478361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69.0</td>\n",
       "      <td>146304.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>7222.440430</td>\n",
       "      <td>4.673050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41.0</td>\n",
       "      <td>37533.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13950.0</td>\n",
       "      <td>12681.626953</td>\n",
       "      <td>9.092280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>76.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7995.0</td>\n",
       "      <td>8440.920898</td>\n",
       "      <td>5.577497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44.0</td>\n",
       "      <td>71793.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14950.0</td>\n",
       "      <td>9425.260742</td>\n",
       "      <td>36.954778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29.0</td>\n",
       "      <td>22575.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16895.0</td>\n",
       "      <td>16393.439453</td>\n",
       "      <td>2.968692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age        KM     HP  MetColor  Automatic      CC  Doors  Weight  \\\n",
       "0   20.0   35000.0   97.0       1.0        0.0  1400.0    5.0  1110.0   \n",
       "1   76.0   89520.0  110.0       1.0        0.0  1600.0    3.0  1050.0   \n",
       "2   56.0   66777.0  110.0       0.0        0.0  1600.0    5.0  1090.0   \n",
       "3   39.0   24723.0  110.0       1.0        1.0  1600.0    4.0  1060.0   \n",
       "4   68.0   35000.0  110.0       1.0        0.0  1600.0    3.0  1050.0   \n",
       "5   68.0  104299.0  110.0       1.0        0.0  1600.0    5.0  1085.0   \n",
       "6   67.0   79762.0   86.0       1.0        0.0  1300.0    3.0  1015.0   \n",
       "7   54.0   47768.0  110.0       0.0        0.0  1600.0    3.0  1055.0   \n",
       "8   28.0   29206.0   97.0       1.0        0.0  1400.0    5.0  1110.0   \n",
       "9   50.0   39706.0  110.0       1.0        0.0  1600.0    5.0  1080.0   \n",
       "10  41.0   30989.0  110.0       0.0        0.0  1600.0    3.0  1045.0   \n",
       "11  66.0   39144.0  110.0       1.0        0.0  1600.0    3.0  1050.0   \n",
       "12  77.0   90305.0   86.0       1.0        0.0  1300.0    3.0  1015.0   \n",
       "13  69.0  146304.0   72.0       1.0        0.0  2000.0    3.0  1115.0   \n",
       "14  41.0   37533.0  110.0       1.0        0.0  1600.0    5.0  1075.0   \n",
       "15  76.0   68000.0  110.0       1.0        0.0  1600.0    5.0  1075.0   \n",
       "16  44.0   71793.0  110.0       1.0        0.0  1600.0    4.0  1067.0   \n",
       "17  29.0   22575.0  110.0       1.0        0.0  1600.0    5.0  1115.0   \n",
       "\n",
       "    FuelType_CNG  FuelType_Diesel  FuelType_Petrol    Price  PredictedPrice  \\\n",
       "0            0.0              0.0              1.0  16500.0    16812.841797   \n",
       "1            0.0              0.0              1.0   8950.0     7863.892578   \n",
       "2            0.0              0.0              1.0  11950.0    10750.361328   \n",
       "3            0.0              0.0              1.0  12695.0    12757.428711   \n",
       "4            0.0              0.0              1.0   8900.0     9312.664062   \n",
       "5            0.0              0.0              1.0   8495.0     8639.937500   \n",
       "6            0.0              0.0              1.0   9130.0     8256.042969   \n",
       "7            0.0              0.0              1.0  10850.0    10543.637695   \n",
       "8            0.0              0.0              1.0  15950.0    15825.493164   \n",
       "9            0.0              0.0              1.0  13500.0    11556.009766   \n",
       "10           0.0              0.0              1.0  12200.0    12622.322266   \n",
       "11           0.0              0.0              1.0   8250.0     9418.009766   \n",
       "12           0.0              0.0              1.0   6950.0     7330.746094   \n",
       "13           0.0              1.0              0.0   6900.0     7222.440430   \n",
       "14           0.0              0.0              1.0  13950.0    12681.626953   \n",
       "15           0.0              0.0              1.0   7995.0     8440.920898   \n",
       "16           1.0              0.0              0.0  14950.0     9425.260742   \n",
       "17           0.0              0.0              1.0  16895.0    16393.439453   \n",
       "\n",
       "          APE  \n",
       "0    1.896011  \n",
       "1   12.135278  \n",
       "2   10.038817  \n",
       "3    0.491758  \n",
       "4    4.636675  \n",
       "5    1.706151  \n",
       "6    9.572366  \n",
       "7    2.823616  \n",
       "8    0.780607  \n",
       "9   14.399928  \n",
       "10   3.461658  \n",
       "11  14.157694  \n",
       "12   5.478361  \n",
       "13   4.673050  \n",
       "14   9.092280  \n",
       "15   5.577497  \n",
       "16  36.954778  \n",
       "17   2.968692  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APE=100* (abs(TestingData['Price']-TestingData['PredictedPrice'])/TestingData['Price'])\n",
    "TestingData['APE']=APE\n",
    "print('The Accuracy of ANN model is:', 100-np.mean(APE))\n",
    "TestingData.head(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>KM</th>\n",
       "      <th>HP</th>\n",
       "      <th>MetColor</th>\n",
       "      <th>Automatic</th>\n",
       "      <th>CC</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FuelType_CNG</th>\n",
       "      <th>FuelType_Diesel</th>\n",
       "      <th>FuelType_Petrol</th>\n",
       "      <th>Price</th>\n",
       "      <th>PredictedPrice</th>\n",
       "      <th>APE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>44.0</td>\n",
       "      <td>131273.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>9305.798828</td>\n",
       "      <td>95.911554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>74.0</td>\n",
       "      <td>203254.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>6052.607910</td>\n",
       "      <td>37.559271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44.0</td>\n",
       "      <td>71793.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14950.0</td>\n",
       "      <td>9425.260742</td>\n",
       "      <td>36.954778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>58.0</td>\n",
       "      <td>69022.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1035.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6950.0</td>\n",
       "      <td>9393.787109</td>\n",
       "      <td>35.162404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>67.0</td>\n",
       "      <td>58058.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12950.0</td>\n",
       "      <td>9173.600586</td>\n",
       "      <td>29.161385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>72.0</td>\n",
       "      <td>105856.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5950.0</td>\n",
       "      <td>7667.109863</td>\n",
       "      <td>28.858989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>69.0</td>\n",
       "      <td>58952.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6900.0</td>\n",
       "      <td>8869.152344</td>\n",
       "      <td>28.538440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>71.0</td>\n",
       "      <td>134660.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5950.0</td>\n",
       "      <td>7592.824707</td>\n",
       "      <td>27.610499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>71.0</td>\n",
       "      <td>64000.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6999.0</td>\n",
       "      <td>8868.553711</td>\n",
       "      <td>26.711726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>68.0</td>\n",
       "      <td>204250.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>5811.849609</td>\n",
       "      <td>26.432283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age        KM     HP  MetColor  Automatic      CC  Doors  Weight  \\\n",
       "295  44.0  131273.0   69.0       1.0        0.0  1800.0    5.0  1110.0   \n",
       "242  74.0  203254.0   72.0       1.0        0.0  2000.0    3.0  1135.0   \n",
       "16   44.0   71793.0  110.0       1.0        0.0  1600.0    4.0  1067.0   \n",
       "143  58.0   69022.0   86.0       1.0        0.0  1300.0    5.0  1035.0   \n",
       "192  67.0   58058.0  110.0       1.0        0.0  1600.0    3.0  1065.0   \n",
       "256  72.0  105856.0   86.0       0.0        0.0  1300.0    3.0  1015.0   \n",
       "268  69.0   58952.0  110.0       1.0        0.0  1600.0    3.0  1050.0   \n",
       "180  71.0  134660.0   72.0       0.0        0.0  2000.0    5.0  1135.0   \n",
       "334  71.0   64000.0  110.0       1.0        0.0  1600.0    5.0  1070.0   \n",
       "398  68.0  204250.0   72.0       0.0        0.0  2000.0    3.0  1115.0   \n",
       "\n",
       "     FuelType_CNG  FuelType_Diesel  FuelType_Petrol    Price  PredictedPrice  \\\n",
       "295           0.0              1.0              0.0   4750.0     9305.798828   \n",
       "242           0.0              1.0              0.0   4400.0     6052.607910   \n",
       "16            1.0              0.0              0.0  14950.0     9425.260742   \n",
       "143           0.0              0.0              1.0   6950.0     9393.787109   \n",
       "192           0.0              0.0              1.0  12950.0     9173.600586   \n",
       "256           0.0              0.0              1.0   5950.0     7667.109863   \n",
       "268           0.0              0.0              1.0   6900.0     8869.152344   \n",
       "180           0.0              1.0              0.0   5950.0     7592.824707   \n",
       "334           0.0              0.0              1.0   6999.0     8868.553711   \n",
       "398           0.0              1.0              0.0   7900.0     5811.849609   \n",
       "\n",
       "           APE  \n",
       "295  95.911554  \n",
       "242  37.559271  \n",
       "16   36.954778  \n",
       "143  35.162404  \n",
       "192  29.161385  \n",
       "256  28.858989  \n",
       "268  28.538440  \n",
       "180  27.610499  \n",
       "334  26.711726  \n",
       "398  26.432283  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing top 10 errors made by model\n",
    "TestingData.sort_values(by='APE', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at the distribution is errors\n",
    "%matplotlib inline\n",
    "TestingData['APE'].hist(figsize=(10,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "TestingData.boxplot(column='APE', figsize=(15,4), vert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Deep ANN model \n",
    "def make_regression_ann(Optimizer_trial):\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Optimizer_trial)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "Parameter_Trials={'batch_size':[10,20,30],\n",
    "                      'epochs':[10,20],\n",
    "                    'Optimizer_trial':['adam', 'rmsprop']\n",
    "                 }\n",
    "\n",
    "\n",
    "RegModel=KerasRegressor(make_regression_ann, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Defining a custom function to calculate accuracy\n",
    "def Accuracy_Score(orig,pred):\n",
    "    MAPE = np.mean(100 * (np.abs(orig-pred)/orig))\n",
    "    print('#'*70,'Accuracy:', 100-MAPE)\n",
    "    return(100-MAPE)\n",
    "\n",
    "custom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Grid search space\n",
    "# See different scoring methods by using sklearn.metrics.SCORERS.keys()\n",
    "grid_search=GridSearchCV(estimator=RegModel, param_grid=Parameter_Trials, scoring=custom_Scoring, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 9s 8ms/step - loss: 0.3194A: 3s - loss\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1278\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0975A:\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0897\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0859\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0848\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0842\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0832\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0829\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0824\n",
      "###################################################################### Accuracy: 20.21612585939947\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1275\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.6656A: 0s - loss\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.2058A:\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1175\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1092A: 1s\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1057A: 0s - los - ETA: 0s - loss: 0.10\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1027\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1008\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0999A: 0s - loss: 0.100\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0970\n",
      "###################################################################### Accuracy: -35.796159564055955\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1307A: 9s -\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.5853\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1569\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1257\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1184\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1132\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1106\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1083A: 0s -\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1081\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1055A: 1s - loss: - ETA: 0s - loss: 0 - ETA: 0s -\n",
      "###################################################################### Accuracy: 149.5851749442263\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.0755\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.6363A:\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.2187\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1416\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1288A: 1s - loss: 0.153 - ETA: \n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1224\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1183A: 0s - loss: 0.1\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1155\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1153\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1130A: 0s - loss: 0.113\n",
      "###################################################################### Accuracy: 119.30252123380609\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 12s 10ms/step - loss: 1.0578\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.6508\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.2025A: 0\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1238\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1146\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1127\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1100\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1092\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1077A:\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1066A: 1 - ETA: 0s - lo\n",
      "###################################################################### Accuracy: 133.73628823501227\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 0.3226\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1511\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1112\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0970A: 0s - loss: 0.11 - ETA: 0s - lo\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0917\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0892\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0871A:\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0857\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0851\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0838A: 0s - lo\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0839\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0829\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0829\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0826\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0819A: \n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0818\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0813\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0808A: 0s -\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0810\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0807A\n",
      "###################################################################### Accuracy: 24.338183775907652\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1523A - ETA: 1s - loss: 1\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.6288\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1442\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1102\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1058\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1029A: 0s - l\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1023\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1013\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0993\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0989A\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0966A:  - ETA: 0s - loss: 0.09\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0959A: 1s  - ETA: 0s - loss: 0.\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0948A: 0s - los\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0932A: \n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0925\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0914\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0907\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0903\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0905\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0905\n",
      "###################################################################### Accuracy: -13.675325505527198\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 10s 9ms/step - loss: 1.1359: 17s - lo - ETA: 7s - lo\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.6312\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1774A: 0s - lo\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1198A: 0s - loss:\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1138\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1098\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1086A: 0s - loss: \n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1073A\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1068\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1038A: 0s - loss: 0.10\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1034\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1034A: 0s - loss: \n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1020A: 0s - loss: 0\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1010\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1018\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1003\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0996\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0998\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0987\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0983\n",
      "###################################################################### Accuracy: 149.76717082788673\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 21s 18ms/step - loss: 1.1069\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.5474\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1358A: 0s - loss: 0.13\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1212\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1163\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1126\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1098\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1085\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1068\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1055A: 0s - l\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1051\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1042\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1030A: 0s - los\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1026\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1021\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1021\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1010A: 0s - los\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1000\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.0996\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.0990\n",
      "###################################################################### Accuracy: 120.07301681317801\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 12s 11ms/step - loss: 1.0685\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.7231A\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.2561\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1358A: 0s - los\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1211\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1171A: 0s - lo\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1154\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1137\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1130\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1104A: \n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1102\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1094\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1085\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1075\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1063A: 0s - ETA: 0s - loss: 0.10\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1066\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1055\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1048\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1044\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1044\n",
      "###################################################################### Accuracy: 134.23617700983223\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 0.3816\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 483us/step - loss: 0.3110\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 483us/step - loss: 0.1920\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 490us/step - loss: 0.1122\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.0967\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.0935\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.0891\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.0876\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.0859\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 483us/step - loss: 0.0852\n",
      "###################################################################### Accuracy: 18.740259125526038\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 1.1712\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 546us/step - loss: 1.0128\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 553us/step - loss: 0.6298\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 750us/step - loss: 0.2725\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1352\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 560us/step - loss: 0.1157\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 511us/step - loss: 0.1091\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 525us/step - loss: 0.1057\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 504us/step - loss: 0.1036\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 525us/step - loss: 0.1016\n",
      "###################################################################### Accuracy: -49.56425828327579\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 1.1700\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 540us/step - loss: 1.0619\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 539us/step - loss: 0.8517\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 507us/step - loss: 0.6412\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 517us/step - loss: 0.4171\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 582us/step - loss: 0.2481\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 552us/step - loss: 0.1583\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 564us/step - loss: 0.1269\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 599us/step - loss: 0.1184\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 552us/step - loss: 0.1148\n",
      "###################################################################### Accuracy: 150.61562164850386\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 7s 6ms/step - loss: 1.1217\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 553us/step - loss: 1.0078\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 476us/step - loss: 0.5988\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 469us/step - loss: 0.2182\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 483us/step - loss: 0.1436\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 490us/step - loss: 0.1316\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 497us/step - loss: 0.1246\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 490us/step - loss: 0.1208 0s - los\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 476us/step - loss: 0.1181\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 651us/step - loss: 0.1155 0s - loss: 0.1\n",
      "###################################################################### Accuracy: 115.63327055535323\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.0837\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 651us/step - loss: 0.9650\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 696us/step - loss: 0.5731\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 665us/step - loss: 0.2096\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 612us/step - loss: 0.1300\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 652us/step - loss: 0.1223\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 637us/step - loss: 0.1182\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 623us/step - loss: 0.1148\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 693us/step - loss: 0.1123\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 714us/step - loss: 0.1104\n",
      "###################################################################### Accuracy: 132.9626929333663\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 6s 5ms/step - loss: 0.3722\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 546us/step - loss: 0.2513\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1547 0s - loss: 0\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 546us/step - loss: 0.1319\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 588us/step - loss: 0.1238\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 532us/step - loss: 0.1181\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 574us/step - loss: 0.1137\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1103\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 546us/step - loss: 0.1077\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 539us/step - loss: 0.1057\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 560us/step - loss: 0.1038\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 652us/step - loss: 0.1019\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 701us/step - loss: 0.1004\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 645us/step - loss: 0.0991\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 673us/step - loss: 0.0973\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 687us/step - loss: 0.0965\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 574us/step - loss: 0.0951\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 589us/step - loss: 0.0938\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 553us/step - loss: 0.0934\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 560us/step - loss: 0.0929\n",
      "###################################################################### Accuracy: 20.996509218339924\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1781\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 701us/step - loss: 1.0557\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 659us/step - loss: 0.6358 0s - loss: 0.7\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 590us/step - loss: 0.2205\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 617us/step - loss: 0.1248\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1135\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 553us/step - loss: 0.1094\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 588us/step - loss: 0.1066\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 574us/step - loss: 0.1049\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 581us/step - loss: 0.1039\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 539us/step - loss: 0.1020\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1017\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 560us/step - loss: 0.1000 0s - loss: - ETA: 0s - loss: 0.099\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 595us/step - loss: 0.0986\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 546us/step - loss: 0.0986\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 560us/step - loss: 0.0983\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 553us/step - loss: 0.0975\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 574us/step - loss: 0.0959\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.0956\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 553us/step - loss: 0.0945\n",
      "###################################################################### Accuracy: -40.47850045430491\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 1.1710A: 14s - l\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 1.0565\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - ETA: 0s - loss: 0.763 - 1s 567us/step - loss: 0.7630\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.4596\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 560us/step - loss: 0.2382\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1511\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 620us/step - loss: 0.1307\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 617us/step - loss: 0.1246 0s - loss: 0.12\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 588us/step - loss: 0.1209\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 574us/step - loss: 0.1206\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 588us/step - loss: 0.1189\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 560us/step - loss: 0.1175\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 574us/step - loss: 0.1165\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1162\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 729us/step - loss: 0.1151\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 708us/step - loss: 0.1145\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 715us/step - loss: 0.1141\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 722us/step - loss: 0.1133\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 680us/step - loss: 0.1139 0s - loss: 0.115 - ETA: 0s - loss: 0.\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 588us/step - loss: 0.1128\n",
      "###################################################################### Accuracy: 154.24859118821954\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 7s 6ms/step - loss: 1.1191\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 551us/step - loss: 0.9850\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 536us/step - loss: 0.5570\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 525us/step - loss: 0.2060\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 616us/step - loss: 0.1362\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 620us/step - loss: 0.1217\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 670us/step - loss: 0.1156\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 671us/step - loss: 0.1110\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 637us/step - loss: 0.1089\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 575us/step - loss: 0.1065\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 616us/step - loss: 0.1054\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 520us/step - loss: 0.1043\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 532us/step - loss: 0.1029\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 530us/step - loss: 0.1026\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 519us/step - loss: 0.1021\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 525us/step - loss: 0.1012\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 526us/step - loss: 0.1004\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 539us/step - loss: 0.0999\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 523us/step - loss: 0.1002\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 1s 525us/step - loss: 0.0994\n",
      "###################################################################### Accuracy: 118.5994565341676\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 7s 6ms/step - loss: 1.0849\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 541us/step - loss: 0.9567\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 532us/step - loss: 0.5379\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 531us/step - loss: 0.2031\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 539us/step - loss: 0.1364\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 547us/step - loss: 0.1244\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 554us/step - loss: 0.1202 0s - lo\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 525us/step - loss: 0.1170\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 595us/step - loss: 0.1152\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 610us/step - loss: 0.1142\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 609us/step - loss: 0.1123\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 598us/step - loss: 0.1113\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 623us/step - loss: 0.1106\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 595us/step - loss: 0.1090\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 623us/step - loss: 0.1078 0s - loss: 0.10\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 568us/step - loss: 0.1077\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 560us/step - loss: 0.1061 0s - loss: 0.106\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 569us/step - loss: 0.1059\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 546us/step - loss: 0.1049\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 1s 583us/step - loss: 0.1051\n",
      "###################################################################### Accuracy: 134.15002740268068\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 6s 6ms/step - loss: 0.3843\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 441us/step - loss: 0.3054\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.1860\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 0s 434us/step - loss: 0.1302\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 458us/step - loss: 0.1129\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 448us/step - loss: 0.1024\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.0969\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 511us/step - loss: 0.0927\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 525us/step - loss: 0.0901\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 532us/step - loss: 0.0881 0s - loss: \n",
      "###################################################################### Accuracy: 24.523675829946086\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1822\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 0s 434us/step - loss: 1.1332\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 0s 421us/step - loss: 0.9561\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 0s 399us/step - loss: 0.6980\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.4462\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.2447\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.1463\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1171\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.1094\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1066\n",
      "###################################################################### Accuracy: -45.57064132133462\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 1.1740\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 1.1340\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.9771\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 0s 406us/step - loss: 0.6652\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 497us/step - loss: 0.3364 0s - loss\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1731\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1343\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 511us/step - loss: 0.1271\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1229\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 490us/step - loss: 0.1202\n",
      "###################################################################### Accuracy: 152.60962432998548\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 7s 6ms/step - loss: 1.1254\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 1.0822\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 0.9303\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 511us/step - loss: 0.6240\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 504us/step - loss: 0.3128\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 539us/step - loss: 0.1752\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 490us/step - loss: 0.1344\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 483us/step - loss: 0.1238\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 483us/step - loss: 0.1176\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 0.1154\n",
      "###################################################################### Accuracy: 118.57104929370408\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 7s 6ms/step - loss: 1.0818\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 0s 392us/step - loss: 1.0087 0s - loss:\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 0s 413us/step - loss: 0.7930\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 483us/step - loss: 0.4788 0s - loss: 0.5\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 469us/step - loss: 0.2471\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 469us/step - loss: 0.1496\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 462us/step - loss: 0.1284\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 0s 434us/step - loss: 0.1232\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 518us/step - loss: 0.1200\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 481us/step - loss: 0.1166\n",
      "###################################################################### Accuracy: 135.62124432668256\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 0.3884\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 0s 387us/step - loss: 0.3333\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 0s 387us/step - loss: 0.2222\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 0s 386us/step - loss: 0.1598\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 0s 374us/step - loss: 0.1450\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 0s 389us/step - loss: 0.1349\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 0s 376us/step - loss: 0.1273\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 442us/step - loss: 0.1217\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 469us/step - loss: 0.1181\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 493us/step - loss: 0.1151\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 521us/step - loss: 0.1125\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 461us/step - loss: 0.1102\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 484us/step - loss: 0.1088\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 443us/step - loss: 0.1070\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 0s 427us/step - loss: 0.1065\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 0s 372us/step - loss: 0.1045\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 0s 374us/step - loss: 0.1039\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 0s 371us/step - loss: 0.1036\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 0s 378us/step - loss: 0.1021\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.1013\n",
      "###################################################################### Accuracy: 19.445903960626367\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 1.1790A: 2s - loss: 1.1\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 525us/step - loss: 1.1335\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 511us/step - loss: 0.9890\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 518us/step - loss: 0.7352 0s - loss: 0.749\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 0s 434us/step - loss: 0.4294\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.2070\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.1240\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.1087\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.1041\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.1021\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 0s 371us/step - loss: 0.1000\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 0s 382us/step - loss: 0.0990\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 0s 380us/step - loss: 0.0978\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 0s 378us/step - loss: 0.0981\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.0967\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 0s 378us/step - loss: 0.0960\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 0s 378us/step - loss: 0.0954\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.0947 0s - loss: 0.095\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 0s 406us/step - loss: 0.0943\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.0938\n",
      "###################################################################### Accuracy: -39.73412440934638\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 7s 6ms/step - loss: 1.1706\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 1.1080\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.8791\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.5062\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.2295\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 0s 378us/step - loss: 0.1448\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 0s 387us/step - loss: 0.1289\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 0s 378us/step - loss: 0.1227\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.1171\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.1145\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 0s 378us/step - loss: 0.1115\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 0s 399us/step - loss: 0.1096 0s - loss: 0\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.1082\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.1076\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.1067\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.1056\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 0s 392us/step - loss: 0.1047\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 0s 385us/step - loss: 0.1050\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 490us/step - loss: 0.1041\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 525us/step - loss: 0.1033\n",
      "###################################################################### Accuracy: 149.8560594561648\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 7s 6ms/step - loss: 1.1289\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 0s 399us/step - loss: 1.1000\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 0s 413us/step - loss: 0.9913\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 0s 406us/step - loss: 0.7737 0s - loss: 0\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 0s 399us/step - loss: 0.5342\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 0s 402us/step - loss: 0.3306\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 0s 399us/step - loss: 0.2016\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 0s 399us/step - loss: 0.1464\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 0s 399us/step - loss: 0.1274\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 0s 406us/step - loss: 0.1198\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 0s 420us/step - loss: 0.1161\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 483us/step - loss: 0.1144\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 476us/step - loss: 0.1119 0s - loss: 0.107\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 518us/step - loss: 0.1107\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 476us/step - loss: 0.1107\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 497us/step - loss: 0.1097\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 455us/step - loss: 0.1092\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 455us/step - loss: 0.1086\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 0s 413us/step - loss: 0.1079\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 0s 406us/step - loss: 0.1073\n",
      "###################################################################### Accuracy: 116.41598186908276\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 7s 6ms/step - loss: 1.0866\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 504us/step - loss: 1.0453\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 490us/step - loss: 0.9048\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 518us/step - loss: 0.6412\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 511us/step - loss: 0.3805\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 511us/step - loss: 0.2231\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 497us/step - loss: 0.1594\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 441us/step - loss: 0.1366\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 0s 386us/step - loss: 0.1275\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 0s 382us/step - loss: 0.1218\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 0s 385us/step - loss: 0.1181\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 0s 379us/step - loss: 0.1160\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 0s 393us/step - loss: 0.1134\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 0s 385us/step - loss: 0.1114\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 0s 392us/step - loss: 0.1099\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 0s 389us/step - loss: 0.1098\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 0s 393us/step - loss: 0.1072\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 0s 390us/step - loss: 0.1067\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 0s 390us/step - loss: 0.1059\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 0s 396us/step - loss: 0.1061\n",
      "###################################################################### Accuracy: 133.35468039493296\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 0.3354A: 5s - lo\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1836\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1164\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0974\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0912\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0889\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0873\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0863\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0854\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0852\n",
      "###################################################################### Accuracy: 22.86013890887105\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1271\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.9239\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.8204\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.7579\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.7009A: 0s -  - ETA: 0s - loss: 0.\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.6529A: 0s - loss: 0.64\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.6003\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.5568\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.5163\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.4810\n",
      "###################################################################### Accuracy: 21.32160324391876\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 10s 9ms/step - loss: 1.1460\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.9042\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.5819\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.3007\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1622\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1301\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1218\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1191A: 0s - los\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1163\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1151\n",
      "###################################################################### Accuracy: 154.70250075107236\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.0824A: 6s -\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.7652A: 0s - l\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.3314\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1520\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1277A: 0s - \n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1200\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1141\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1119\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1104\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1076\n",
      "###################################################################### Accuracy: 117.56922118870956\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.0447\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.6753\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.2365\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1400\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1279\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1211\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1188\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1148\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1128A: 0s - loss: 0 - ETA: 0s - los\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1108\n",
      "###################################################################### Accuracy: 133.06913907522448\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 9s 7ms/step - loss: 0.3487\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 2s 2ms/step - loss: 0.2267A: 0s \n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1408A: 0s - l\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1074\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0943\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0902\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0878A: 0s - loss: 0.\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0865\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0855\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0847\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0843A: 0s - loss\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0838\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0834\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0830\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0823\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0824\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0820\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0818\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0813\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 2s 2ms/step - loss: 0.0813\n",
      "###################################################################### Accuracy: 20.119195245424507\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1067\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.7055\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.2886A: 0s - loss\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1238\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1074\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1043\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1025\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1017\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0994\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0997\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0983A: 0s - loss\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0974\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0957\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0958\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0950\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.0944\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0936\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0926\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0930\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.0923\n",
      "###################################################################### Accuracy: -22.202983119316812\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1203\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.7707\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.3777\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.2113\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1537\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1340\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1243\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1196\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1170A: 0s - loss: 0.11\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1145A: 0s - \n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 2s 1ms/step - loss: 0.1122\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1113\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1090\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1080\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1074\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1065\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1061\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1050\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1041\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 1ms/step - loss: 0.1032\n",
      "###################################################################### Accuracy: 154.41121769730213\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.1028\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.8942\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.5929\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.3299\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1816A: 0s - loss: 0 - ETA: 0s - loss: 0.2 - ETA: 0s - lo\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1368\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1242\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1189\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1154\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1132A: 0s -\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1116\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1107\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1085\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1076\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1076A: 0s -  - ETA: 0s - loss: 0.1\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - ETA: 0s - loss: 0.107 - 2s 1ms/step - loss: 0.1072\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1055\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1048\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1043\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1036\n",
      "###################################################################### Accuracy: 119.46226954501275\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 9s 8ms/step - loss: 1.0141\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.7122\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.3576A: 0\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.2383\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1935\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1725\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1599\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1521A: 0s - loss:\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1453\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 2s 2ms/step - loss: 0.1404\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1364\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1330\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1303\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1268\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1251A: 0s -\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1225\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1206\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1190\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 1ms/step - loss: 0.1166\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 2s 1ms/step - loss: 0.1150A\n",
      "###################################################################### Accuracy: 132.30586382107285\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 0.3547\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 666us/step - loss: 0.2301 0s - loss: 0\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 778us/step - loss: 0.1690 0s - \n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 804us/step - loss: 0.1421\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 820us/step - loss: 0.1249\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 792us/step - loss: 0.1154 0s - loss: 0.\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 778us/step - loss: 0.1084\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 722us/step - loss: 0.1040\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 701us/step - loss: 0.1003 0s - loss: 0.1\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 736us/step - loss: 0.0975\n",
      "###################################################################### Accuracy: 22.221421841959625\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 9s 8ms/step - loss: 1.1647A: 24s -\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 652us/step - loss: 1.0569 0s - loss: 1.0 - ETA: 0s - loss: 1.063\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 652us/step - loss: 0.8448\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 673us/step - loss: 0.6082\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 629us/step - loss: 0.3987\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 659us/step - loss: 0.2355\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 654us/step - loss: 0.1370\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 646us/step - loss: 0.1122\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 597us/step - loss: 0.1065\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 645us/step - loss: 0.1045\n",
      "###################################################################### Accuracy: -27.113824113465782\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1640\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 662us/step - loss: 1.0659 0s - loss:\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 666us/step - loss: 0.8426\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 653us/step - loss: 0.5511\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 632us/step - loss: 0.2978\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 610us/step - loss: 0.1777\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 647us/step - loss: 0.1382\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 647us/step - loss: 0.1282\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 750us/step - loss: 0.1232\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 721us/step - loss: 0.1208\n",
      "###################################################################### Accuracy: 155.3422480830425\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.1252\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 815us/step - loss: 1.0728 0s - l\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 812us/step - loss: 0.9307\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 826us/step - loss: 0.7046 0s - loss\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 784us/step - loss: 0.4461\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 679us/step - loss: 0.2528\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 672us/step - loss: 0.1581 0s - loss: 0.\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 644us/step - loss: 0.1365\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 678us/step - loss: 0.1282\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 714us/step - loss: 0.1232\n",
      "###################################################################### Accuracy: 123.89442436239017\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.0771\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 630us/step - loss: 0.9766\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 628us/step - loss: 0.7673\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 715us/step - loss: 0.4836\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 699us/step - loss: 0.2584\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 648us/step - loss: 0.1610\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 679us/step - loss: 0.1350\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 658us/step - loss: 0.1269 0s - los\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 633us/step - loss: 0.1229\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 630us/step - loss: 0.1199\n",
      "###################################################################### Accuracy: 134.50821651914475\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 0.3698\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 666us/step - loss: 0.2877\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 645us/step - loss: 0.1959\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 715us/step - loss: 0.1399 0s - loss: 0.1\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 687us/step - loss: 0.1120\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 680us/step - loss: 0.0999\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 799us/step - loss: 0.0940\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 869us/step - loss: 0.0906\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 890us/step - loss: 0.0887\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 869us/step - loss: 0.0875\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 760us/step - loss: 0.0865\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 694us/step - loss: 0.0858\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 701us/step - loss: 0.0850\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 743us/step - loss: 0.0846 0s - loss: 0.08 - ETA: 0s - loss: 0.08 - ETA: 0s - loss: 0.084\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 690us/step - loss: 0.0840\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 680us/step - loss: 0.0834\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 680us/step - loss: 0.0836\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 680us/step - loss: 0.0832 0s - loss\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 666us/step - loss: 0.0831\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 653us/step - loss: 0.0829\n",
      "###################################################################### Accuracy: 19.790869144549845\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1714\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 670us/step - loss: 1.0857 0s - loss: 1.066\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 652us/step - loss: 0.9166\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 652us/step - loss: 0.7006\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 631us/step - loss: 0.5095\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 659us/step - loss: 0.3254 0s - loss: 0. - ETA: 0s - loss: 0.\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 743us/step - loss: 0.1978\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 809us/step - loss: 0.1378 0s - loss\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 792us/step - loss: 0.1178 0s - loss: 0.1\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 785us/step - loss: 0.1106\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 743us/step - loss: 0.1065\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 637us/step - loss: 0.1041\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 645us/step - loss: 0.1024 0s - lo\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 610us/step - loss: 0.1004\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 659us/step - loss: 0.0988\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 636us/step - loss: 0.0973\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 652us/step - loss: 0.0957\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 659us/step - loss: 0.0951\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 638us/step - loss: 0.0948\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 722us/step - loss: 0.0938\n",
      "###################################################################### Accuracy: -36.330206554022936\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1584\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 694us/step - loss: 1.0362\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 708us/step - loss: 0.7751\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 673us/step - loss: 0.4449 0s - loss: 0.\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 687us/step - loss: 0.2324\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 652us/step - loss: 0.1533\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 659us/step - loss: 0.1350\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 666us/step - loss: 0.1269\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 673us/step - loss: 0.1215 0s - loss: 0.1 - ETA: 0s - loss: 0.\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 743us/step - loss: 0.1182 0s - loss\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 801us/step - loss: 0.1155 0s - lo\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 915us/step - loss: 0.1136\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 911us/step - loss: 0.1119\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 799us/step - loss: 0.1109\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 834us/step - loss: 0.1096 0s - loss:  - ETA: 0s - loss: 0\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 670us/step - loss: 0.1088\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 659us/step - loss: 0.1082\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 759us/step - loss: 0.1072\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 638us/step - loss: 0.1068\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 645us/step - loss: 0.1064\n",
      "###################################################################### Accuracy: 155.1130706228988\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 9s 8ms/step - loss: 1.1080\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 716us/step - loss: 1.0216\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 623us/step - loss: 0.8674\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 637us/step - loss: 0.6526\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 731us/step - loss: 0.4121 0s - loss:  - ETA: 0s - loss: 0.\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 691us/step - loss: 0.2357\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 707us/step - loss: 0.1608\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 744us/step - loss: 0.1407\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 803us/step - loss: 0.1320\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 805us/step - loss: 0.1256\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 783us/step - loss: 0.1223\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 756us/step - loss: 0.1190\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 697us/step - loss: 0.1158\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 672us/step - loss: 0.1139\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 651us/step - loss: 0.1126\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 644us/step - loss: 0.1109\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 653us/step - loss: 0.1093\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 861us/step - loss: 0.1085\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 847us/step - loss: 0.1070 0s - loss: \n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 1s 826us/step - loss: 0.1067\n",
      "###################################################################### Accuracy: 118.40814002567238\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.0325\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 632us/step - loss: 0.8115\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 656us/step - loss: 0.5206\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 672us/step - loss: 0.2809\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 631us/step - loss: 0.1770\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 646us/step - loss: 0.1400\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 777us/step - loss: 0.1293\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 861us/step - loss: 0.1249\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 812us/step - loss: 0.1201\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 826us/step - loss: 0.1166\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 672us/step - loss: 0.1137\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 659us/step - loss: 0.1113\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 651us/step - loss: 0.1100 0s - los\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 695us/step - loss: 0.1086\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 707us/step - loss: 0.1078\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 686us/step - loss: 0.1062\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 665us/step - loss: 0.1056\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 679us/step - loss: 0.1051\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 693us/step - loss: 0.1049\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 1s 651us/step - loss: 0.1040\n",
      "###################################################################### Accuracy: 134.4207470776222\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 0.3746\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 0s 434us/step - loss: 0.3061\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 0s 427us/step - loss: 0.2339\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 469us/step - loss: 0.1849 0s - loss: 0\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.1585\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 546us/step - loss: 0.1417\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 532us/step - loss: 0.1287\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 567us/step - loss: 0.1183\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 553us/step - loss: 0.1102\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 546us/step - loss: 0.1046\n",
      "###################################################################### Accuracy: 16.337034574543722\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 9s 8ms/step - loss: 1.1826\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 518us/step - loss: 1.1368\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 497us/step - loss: 1.0146\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.8144\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 448us/step - loss: 0.5562\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.3204\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.1682\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 511us/step - loss: 0.1262\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 490us/step - loss: 0.1167\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1129\n",
      "###################################################################### Accuracy: -57.64409412748631\n",
      "Epoch 1/10\n",
      "1142/1142 [==============================] - 9s 8ms/step - loss: 1.1517A: 18s - los\n",
      "Epoch 2/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 1.0479 0s - loss\n",
      "Epoch 3/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.8665\n",
      "Epoch 4/10\n",
      "1142/1142 [==============================] - 1s 448us/step - loss: 0.6300\n",
      "Epoch 5/10\n",
      "1142/1142 [==============================] - 1s 465us/step - loss: 0.4058\n",
      "Epoch 6/10\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.2511\n",
      "Epoch 7/10\n",
      "1142/1142 [==============================] - 1s 448us/step - loss: 0.1745\n",
      "Epoch 8/10\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.1401\n",
      "Epoch 9/10\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1282\n",
      "Epoch 10/10\n",
      "1142/1142 [==============================] - 0s 434us/step - loss: 0.1226\n",
      "###################################################################### Accuracy: 159.58707133810978\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.1216A: 1s - loss: 1.07\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 490us/step - loss: 1.0638\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 0.9444\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 469us/step - loss: 0.7624\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 504us/step - loss: 0.5535\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 546us/step - loss: 0.3561\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 518us/step - loss: 0.2336 0s - loss\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 581us/step - loss: 0.1720\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 557us/step - loss: 0.1438\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 623us/step - loss: 0.1312\n",
      "###################################################################### Accuracy: 113.11131749593395\n",
      "Epoch 1/10\n",
      "1143/1143 [==============================] - 9s 8ms/step - loss: 1.0802\n",
      "Epoch 2/10\n",
      "1143/1143 [==============================] - 1s 469us/step - loss: 1.0120\n",
      "Epoch 3/10\n",
      "1143/1143 [==============================] - 0s 413us/step - loss: 0.8702\n",
      "Epoch 4/10\n",
      "1143/1143 [==============================] - 1s 476us/step - loss: 0.6727\n",
      "Epoch 5/10\n",
      "1143/1143 [==============================] - 1s 518us/step - loss: 0.4572\n",
      "Epoch 6/10\n",
      "1143/1143 [==============================] - 1s 482us/step - loss: 0.2673\n",
      "Epoch 7/10\n",
      "1143/1143 [==============================] - 1s 449us/step - loss: 0.1785\n",
      "Epoch 8/10\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 0.1471\n",
      "Epoch 9/10\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 0.1338 0s - loss:\n",
      "Epoch 10/10\n",
      "1143/1143 [==============================] - 1s 441us/step - loss: 0.1272\n",
      "###################################################################### Accuracy: 133.8103880952021\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 10s 9ms/step - loss: 0.3793: 3s - loss: 0.3\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 450us/step - loss: 0.3258\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.2603\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 0s 435us/step - loss: 0.2019\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 440us/step - loss: 0.1623\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 449us/step - loss: 0.1354\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 451us/step - loss: 0.1176\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 490us/step - loss: 0.1055\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 0s 419us/step - loss: 0.0978\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.0936\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.0904\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 0s 429us/step - loss: 0.0883\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 472us/step - loss: 0.0873\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 539us/step - loss: 0.0864\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 578us/step - loss: 0.0861\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 581us/step - loss: 0.0853\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 574us/step - loss: 0.0849\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 553us/step - loss: 0.0848\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 537us/step - loss: 0.0843\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.0840\n",
      "###################################################################### Accuracy: 24.17561157879183\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1820\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 490us/step - loss: 1.1467\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 0s 413us/step - loss: 1.0606\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 465us/step - loss: 0.9270\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 448us/step - loss: 0.7722\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 470us/step - loss: 0.6150\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 0s 420us/step - loss: 0.4751 0s - loss: 0.\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - 1s 442us/step - loss: 0.3522\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 518us/step - loss: 0.2492 0s - loss: 0.2\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 504us/step - loss: 0.1698\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 518us/step - loss: 0.1301\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.1162\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 483us/step - loss: 0.1114\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 469us/step - loss: 0.1092 0s - loss: 0.109\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 470us/step - loss: 0.1068\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 469us/step - loss: 0.1059\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 456us/step - loss: 0.1043\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1045\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 504us/step - loss: 0.1034\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 504us/step - loss: 0.1030\n",
      "###################################################################### Accuracy: -35.32940032491422\n",
      "Epoch 1/20\n",
      "1142/1142 [==============================] - 8s 7ms/step - loss: 1.1636TA: 22s - l\n",
      "Epoch 2/20\n",
      "1142/1142 [==============================] - 1s 479us/step - loss: 1.0852\n",
      "Epoch 3/20\n",
      "1142/1142 [==============================] - 1s 581us/step - loss: 0.9356 0s - loss: 0.96\n",
      "Epoch 4/20\n",
      "1142/1142 [==============================] - 1s 610us/step - loss: 0.7232\n",
      "Epoch 5/20\n",
      "1142/1142 [==============================] - 1s 595us/step - loss: 0.4746\n",
      "Epoch 6/20\n",
      "1142/1142 [==============================] - 1s 581us/step - loss: 0.2794\n",
      "Epoch 7/20\n",
      "1142/1142 [==============================] - 1s 588us/step - loss: 0.1731\n",
      "Epoch 8/20\n",
      "1142/1142 [==============================] - ETA: 0s - loss: 0.142 - 1s 525us/step - loss: 0.1428\n",
      "Epoch 9/20\n",
      "1142/1142 [==============================] - 1s 441us/step - loss: 0.1329\n",
      "Epoch 10/20\n",
      "1142/1142 [==============================] - 1s 476us/step - loss: 0.1270\n",
      "Epoch 11/20\n",
      "1142/1142 [==============================] - 1s 510us/step - loss: 0.1235\n",
      "Epoch 12/20\n",
      "1142/1142 [==============================] - 1s 448us/step - loss: 0.1200\n",
      "Epoch 13/20\n",
      "1142/1142 [==============================] - 1s 497us/step - loss: 0.1175\n",
      "Epoch 14/20\n",
      "1142/1142 [==============================] - 1s 504us/step - loss: 0.1159 0s - loss: 0.1\n",
      "Epoch 15/20\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.1146\n",
      "Epoch 16/20\n",
      "1142/1142 [==============================] - 1s 492us/step - loss: 0.1127\n",
      "Epoch 17/20\n",
      "1142/1142 [==============================] - 1s 469us/step - loss: 0.1110\n",
      "Epoch 18/20\n",
      "1142/1142 [==============================] - 1s 455us/step - loss: 0.1101\n",
      "Epoch 19/20\n",
      "1142/1142 [==============================] - 1s 497us/step - loss: 0.1091\n",
      "Epoch 20/20\n",
      "1142/1142 [==============================] - 1s 462us/step - loss: 0.1082\n",
      "###################################################################### Accuracy: 151.51557796344514\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 8s 7ms/step - loss: 1.1262\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 1.0917\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 476us/step - loss: 1.0141\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 0.9039\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 476us/step - loss: 0.7880 0s - loss: 0.74 - ETA: 0s - loss: \n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 448us/step - loss: 0.6859\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 497us/step - loss: 0.5844\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 441us/step - loss: 0.4905\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 539us/step - loss: 0.4028\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 539us/step - loss: 0.3239\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 588us/step - loss: 0.2565\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 623us/step - loss: 0.1942\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 609us/step - loss: 0.1581\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 637us/step - loss: 0.1348\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 602us/step - loss: 0.1236\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 574us/step - loss: 0.1192\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 539us/step - loss: 0.1165\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 481us/step - loss: 0.1150\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 494us/step - loss: 0.1136 0s - loss: 0.11 - ETA: 0s - loss: 0.1\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 1s 485us/step - loss: 0.1133\n",
      "###################################################################### Accuracy: 117.69272621181288\n",
      "Epoch 1/20\n",
      "1143/1143 [==============================] - 9s 8ms/step - loss: 1.0836\n",
      "Epoch 2/20\n",
      "1143/1143 [==============================] - 1s 465us/step - loss: 1.0348\n",
      "Epoch 3/20\n",
      "1143/1143 [==============================] - 1s 512us/step - loss: 0.9396\n",
      "Epoch 4/20\n",
      "1143/1143 [==============================] - 1s 511us/step - loss: 0.7987\n",
      "Epoch 5/20\n",
      "1143/1143 [==============================] - 1s 584us/step - loss: 0.6384\n",
      "Epoch 6/20\n",
      "1143/1143 [==============================] - 1s 574us/step - loss: 0.4764\n",
      "Epoch 7/20\n",
      "1143/1143 [==============================] - 1s 532us/step - loss: 0.3366\n",
      "Epoch 8/20\n",
      "1143/1143 [==============================] - 1s 581us/step - loss: 0.2350\n",
      "Epoch 9/20\n",
      "1143/1143 [==============================] - 1s 639us/step - loss: 0.1784\n",
      "Epoch 10/20\n",
      "1143/1143 [==============================] - 1s 567us/step - loss: 0.1479\n",
      "Epoch 11/20\n",
      "1143/1143 [==============================] - 1s 582us/step - loss: 0.1326\n",
      "Epoch 12/20\n",
      "1143/1143 [==============================] - 1s 581us/step - loss: 0.1258\n",
      "Epoch 13/20\n",
      "1143/1143 [==============================] - 1s 560us/step - loss: 0.1213\n",
      "Epoch 14/20\n",
      "1143/1143 [==============================] - 1s 469us/step - loss: 0.1187\n",
      "Epoch 15/20\n",
      "1143/1143 [==============================] - 1s 464us/step - loss: 0.1163\n",
      "Epoch 16/20\n",
      "1143/1143 [==============================] - 1s 483us/step - loss: 0.1144 0s - loss: 0.115 - ETA: 0s - loss: 0.11\n",
      "Epoch 17/20\n",
      "1143/1143 [==============================] - 1s 532us/step - loss: 0.1129\n",
      "Epoch 18/20\n",
      "1143/1143 [==============================] - 1s 483us/step - loss: 0.1122\n",
      "Epoch 19/20\n",
      "1143/1143 [==============================] - 1s 462us/step - loss: 0.1107\n",
      "Epoch 20/20\n",
      "1143/1143 [==============================] - 1s 515us/step - loss: 0.1092\n",
      "###################################################################### Accuracy: 132.88738901108218\n",
      "Epoch 1/10\n",
      "1428/1428 [==============================] - 10s 7ms/step - loss: 0.9603\n",
      "Epoch 2/10\n",
      "1428/1428 [==============================] - 2s 1ms/step - loss: 0.6872\n",
      "Epoch 3/10\n",
      "1428/1428 [==============================] - 2s 1ms/step - loss: 0.3745\n",
      "Epoch 4/10\n",
      "1428/1428 [==============================] - 2s 1ms/step - loss: 0.1862\n",
      "Epoch 5/10\n",
      "1428/1428 [==============================] - 2s 2ms/step - loss: 0.1246\n",
      "Epoch 6/10\n",
      "1428/1428 [==============================] - 2s 2ms/step - loss: 0.1147A: 2s - l -\n",
      "Epoch 7/10\n",
      "1428/1428 [==============================] - 2s 1ms/step - loss: 0.1098\n",
      "Epoch 8/10\n",
      "1428/1428 [==============================] - 2s 1ms/step - loss: 0.1082\n",
      "Epoch 9/10\n",
      "1428/1428 [==============================] - 2s 1ms/step - loss: 0.1064\n",
      "Epoch 10/10\n",
      "1428/1428 [==============================] - 2s 2ms/step - loss: 0.1048\n",
      "########## Total Time Taken:  45 Minutes\n"
     ]
    }
   ],
   "source": [
    "# Measuring how much time it took to find the best params\n",
    "import time\n",
    "StartTime=time.time()\n",
    "\n",
    "# Running Grid Search for different paramenters\n",
    "grid_search.fit(X,y, verbose=1)\n",
    "\n",
    "EndTime=time.time()\n",
    "print(\"########## Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Optimizer_trial': 'rmsprop', 'batch_size': 10, 'epochs': 10}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
